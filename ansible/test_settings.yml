# Debug mode (Will print out extra debug information. Only enable if asked to by RedHat)
redhat_debug_mode: True

# Red Hat subscription username, password, pool_id used for accessing Red Hat repositories.  If you do not have one
# please ask your Red Hat EPM to assist.
rh_sub_username:
rh_sub_pass:
rh_sub_pool_id:

# enable the below if internally testing for QE and use the command found at -> https://wiki.test.redhat.com/ctrautma
# and search for the section Subscription manager testing and enclose it with ""
# DO NOT COMMIT THIS FILE TO GITHUB if this change is made!!!!!
qe_subscription_mode: false
qe_subscription_command:

# Alternate solution to subscription manager, allows custom repos to be used instead
custom_repo_setup: true
custom_repo_path: "http://9.114.224.56/~drc/ftp3.repo"

# T-Rex version to use (example v2.53 : Note please include the v) This is the version that will be downloaded from git
# and installed on the trex server.
trex_path: https://trex-tgn.cisco.com/trex/release
trex_version: v2.72

# T-Rex server NIC names (example eth1, enp68s0f0, etc...)
trex_interface_1: ens4f0
trex_interface_2: ens4f1
trex_interface_1_pciid: "0000:58:00.0"
trex_interface_2_pciid: "0000:58:00.1"

# Openvswitch package location. While you can pull this from the fast datapath repository it is recommended to contact
# your development representative to get the latest version. Then copy this to the DUT and specify its location.
ovs_rpm_path: "http://9.114.224.56/~drc/openvswitch2.11-2.11.0-26.el8.ppc64le.rpm"

# Openvswitch selinux package location. While you can pull this from the fast datapath repository it is recommended to
# contact your development representative to get the latest version.  Then copy this to the DUT and specify its location.
ovs_selinux_rpm_path: "http://9.114.224.56/~drc/openvswitch-selinux-extra-policy-1.0-19.el8.noarch.rpm"

# DUT server isolated core list
dut_isolated_cpus: 4-63

# VM isolated core list (x86_64 should use 1,2,3 and Power should use 1,2,3,4,5)
#vm_isolated_cpus: 1,2,3
vm_isolated_cpus: 1,2,3,4,5

# DUT NIC Device names
#DRC - MLX5 (NUMA node 0)
#dut_interface_1: enp1s0f0
#dut_interface_2: enp1s0f1
#dut_interface_1_pciid: "0000:01:00.0"
#dut_interface_2_pciid: "0000:01:00.1"

#DRC - i40e (NUMA node 8)
dut_interface_1: enP52p1s0f0
dut_interface_2: enP52p1s0f1
dut_interface_1_pciid: "0034:01:00.0"
dut_interface_2_pciid: "0034:01:00.1"

tc_offload_card_type: "Unknown"

# DUT DPDK Driver. For most devices this will be vfio-pci, but some NICs such as Mellanox ConnectX-5 don't
# user access to hardware registers, so the driver should be "none".
# dut_driver: vfio-pci
# dut_driver: none
dut_driver: vfio-pci
trex_driver: vfio-pci

# DUT DPDK PMD Mask.  PMD mask to set for which cores will be used for PMD threads.
# DRC - Is this for OVS????
#dut_dpdk_pmd_mask: 8002

# DUT DPDK L-Core Mask.  Core mask for the logical core,  should not conflict with DPDK PMD mask.  Does not have to align with NUMA of NIC.
# DRC - Currently ignored in favor of get_cpulist.sh
#dut_dpdk_lcore_mask: 4-63

# DUT PMD RXQ Affinity. The receive queue affinity which will be set on the PMD threads.
# DRC - Should we have two, one for each port on the adapter?
# DRC - Currently ignored in favor of get_cpulist.sh
#dut_pmd_rxq_affinity: 0:8,1:9,2:10,3:11,4:12,5:13,6:14,7:15
# dut_pmd_rxq_affinity: 0:16,1:17,2:18,3:19,4:20,5:21,6:22,7:23

# Path to RHEL guest image for PVP tests.  Please download the image from the red hat website.  See README for more info.
# This is the location where the file is located on the DUT.
rhel_guest_image_path: /home/vm/images/rhel-guest-image-8.1-263.ppc64le.qcow2

# CPU model info, needs to be modified to match your DUT cpu type. If an error occurs with virt-install might need to
# modify this line to a model present in  /usr/share/libvirt/cpu_map.xml
#dut_cpu_model: SandyBridge
#dut_cpu_model: Haswell-noTSX
dut_cpu_model: POWER9

# Set the hugepage variables for the Linux kernel command-line
dut_hugepages: 32
dut_hugepagesz: 1G
dut_default_hugepagesz: 1G

trex_hugepages: 32
trex_hugepagesz: 1G
trex_default_hugepagesz: 1G

# x86 based systems typically require "pt", Power based systems should select "none"
dut_iommu_mode: "none"
trex_iommu_mode: "pt"

# x86 based systems will require "on", Power based systems ignore this setting
dut_intel_iommu_mode: "on"
trex_intel_iommu_mode: "on"
